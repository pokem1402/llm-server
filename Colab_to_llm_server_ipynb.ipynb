{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoIxquAlJ2Wl"
      },
      "source": [
        "# GPU 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BWf_RA6J6pJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "assert torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZG1H6pdKRAG"
      },
      "outputs": [],
      "source": [
        "# Google Drive Mount\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzroHQLELZfN"
      },
      "source": [
        "# Install text-generation web ui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQmJmY2A8c-N"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5Qi2pWMUWlb"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/oobabooga/text-generation-webui.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uu3f5NQ2UbMf"
      },
      "outputs": [],
      "source": [
        "!pip install -r ./text-generation-webui/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRcyVEBWWHsP"
      },
      "source": [
        "# load Some file to colab local drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDqd3PJcUO3o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "web_ui_path = Path(\"/content/text-generation-webui/\")\n",
        "model_file_name = \"synatra-7b_q8_0.bin\"\n",
        "model_file_path = Path(\"/content/drive/MyDrive/자료\") / model_file_name\n",
        "dest_model_path = web_ui_path / \"models\" / model_file_name\n",
        "assert os.path.exists(model_file_path), model_file_path\n",
        "\n",
        "if not os.path.exists(dest_model_path):\n",
        "  !cp {model_file_path} {dest_model_path}\n",
        "  print(\"model file has been loaded\")\n",
        "else:\n",
        "  print(\"model file was loaded already\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeaEAxTsdgVq"
      },
      "source": [
        "# LLM Local Model Configuration\n",
        "\n",
        "https://github.com/oobabooga/text-generation-webui/blob/main/settings-template.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFddJ13ddfTw"
      },
      "outputs": [],
      "source": [
        "custom_config = {\n",
        "    \"max_new_tokens\" : 1024,\n",
        "    \"truncation_length\" : 5120,\n",
        "    \"instruction_template\" : \"Mistral\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzKHxNYQci-R"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "from pprint import pprint\n",
        "\n",
        "config_template_file_name = \"settings-template.yaml\"\n",
        "config_template_path = web_ui_path / config_template_file_name\n",
        "\n",
        "with open(config_template_path, 'r') as f:\n",
        "  config  = yaml.safe_load(f)\n",
        "\n",
        "config = {**config, **custom_config}\n",
        "pprint(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbrSciEcmS4F"
      },
      "source": [
        "# API extension 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akQL1UI7mRjF"
      },
      "outputs": [],
      "source": [
        "!pip install -r ./extensions/api/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JADU4zrmmP38"
      },
      "source": [
        "# Server 구동"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boPHWaWv2GzW"
      },
      "outputs": [],
      "source": [
        "n_gpu_layers = 35\n",
        "n_ctx = 5120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHaCDSkW-QH0"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KSNHp2HbOCT"
      },
      "outputs": [],
      "source": [
        "!python server.py --model {model_file_name} --loader llamacpp --n-gpu-layers {str(n_gpu_layers)} --n_ctx {str(n_ctx)} \\\n",
        "--api --public-api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfHZJ9CNLK7Z"
      },
      "source": [
        "# Colab-SSH 설치 및 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeAuUMaZLJ8p"
      },
      "outputs": [],
      "source": [
        "# !pip install colab-ssh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3QK__fGLSjV"
      },
      "outputs": [],
      "source": [
        "# from colab_ssh import launch_ssh\n",
        "# launch_ssh(NGROK_TOKEN, PASSWORD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_SM8GRhJ09q"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# I = np.eye(3)\n",
        "\n",
        "# while True:\n",
        "#   I = I@I"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}